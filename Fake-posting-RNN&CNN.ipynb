{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c739b5",
   "metadata": {},
   "source": [
    "### Yunhe Jia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5adfd5c-c155-444d-beeb-89161a51b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import spacy\n",
    "import re\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73ae3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./fake_job_postings.csv')\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "74214c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td></td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td></td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td></td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing               We're Food52, and we've created a groundbreaki...   \n",
       "1    Success               90 Seconds, the worlds Cloud Video Production ...   \n",
       "2                          Valor Services provides Workforce Solutions th...   \n",
       "3      Sales               Our passion for improving quality of life thro...   \n",
       "4                          SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                                 0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                                 0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0                                       \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                                                           Marketing   \n",
       "1                     Marketing and Advertising      Customer Service   \n",
       "2                                                                       \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent                                               comb  \n",
       "0           0  Food52, a fast-growing, James Beard Award-winn...  \n",
       "1           0  Organised - Focused - Vibrant - Awesome!Do you...  \n",
       "2           0  Our client, located in Houston, is actively se...  \n",
       "3           0  THE COMPANY: ESRI – Environmental Systems Rese...  \n",
       "4           0  JOB TITLE: Itemization Review ManagerLOCATION:...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b600bd",
   "metadata": {},
   "source": [
    "combine three columns for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb75e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comb'] = data['description']+data['requirements']+data['benefits']\n",
    "df = data[['comb','fraudulent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe49379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comb  fraudulent\n",
       "0  Food52, a fast-growing, James Beard Award-winn...           0\n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...           0\n",
       "2  Our client, located in Houston, is actively se...           0\n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...           0\n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...           0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b11760",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a460b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c40192989d84871b338e05cf9de0f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>0</td>\n",
       "      <td>food fast grow james beard award win online fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>0</td>\n",
       "      <td>organise focus vibrant awesome passion custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>0</td>\n",
       "      <td>client locate houston actively seek experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>0</td>\n",
       "      <td>company esri environmental system research ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>0</td>\n",
       "      <td>job title itemization review managerlocation f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comb  fraudulent  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...           0   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...           0   \n",
       "2  Our client, located in Houston, is actively se...           0   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...           0   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...           0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  food fast grow james beard award win online fo...  \n",
       "1  organise focus vibrant awesome passion custome...  \n",
       "2  client locate houston actively seek experience...  \n",
       "3  company esri environmental system research ins...  \n",
       "4  job title itemization review managerlocation f...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disabling some fancy features of spacy for speed\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "rows = []\n",
    "for idx in tqdm(range(len(df))):\n",
    "    row = df.iloc[idx].copy()\n",
    "    \n",
    "    # first we remove numeric characters and lowercase everything\n",
    "    cleaned_head = re.sub(\"[^A-Za-z']+\", ' ', row['comb']).replace(\"'\", ' ').lower()\n",
    "    \n",
    "    # we let spaCy tokenize and lemmatize the text for us\n",
    "    tokenized_head = nlp(cleaned_head)\n",
    "    cleaned_tokenized = [token.lemma_ for token in tokenized_head if ((not token.is_stop) or (' ' in token.text))]\n",
    "    \n",
    "    if len(cleaned_tokenized) > 1:\n",
    "        row['cleaned'] = ' '.join(cleaned_tokenized)\n",
    "    rows.append(row)\n",
    "df_clean = pd.DataFrame(rows)\n",
    "df_clean = df_clean[~df_clean.cleaned.isna()]\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdf6adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('./job_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b265f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train,df_valid = train_test_split(df_clean,train_size=0.7,random_state=30)\n",
    "df_valid,df_test = train_test_split(df_valid,train_size=0.5,random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd434d-a060-40b6-89b2-a7d745efe03c",
   "metadata": {},
   "source": [
    "## Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "451dfe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12635"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "headlines = [headline.split(' ') for headline in list(df_train['cleaned'])]\n",
    "word_freq = Counter([token for headline in headlines for token in headline]).most_common()\n",
    "\n",
    "# # remove words that appear infrequently\n",
    "word_freq = dict(word_freq)\n",
    "# print(len(word_freq))\n",
    "min_freq = 5\n",
    "word_dict = {}\n",
    "\n",
    "# # sending all the unknowns to 0\n",
    "i = 1\n",
    "for word in word_freq:\n",
    "    if word_freq[word] > min_freq:\n",
    "        word_dict[word] = i\n",
    "        i += 1\n",
    "    else:\n",
    "        word_dict[word] = 0\n",
    "\n",
    "# dictionary length        \n",
    "dict_length = max(word_dict.values()) + 1\n",
    "dict_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "481996b9-1b4d-457f-869e-3665b48f0b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47d1679220a446abc5cabe24a894722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for idx in tqdm(range(len(df_train))):\n",
    "#     print ()\n",
    "    row = df_train.iloc[idx]\n",
    "#     print (row)\n",
    "    length = len(row['cleaned'].split(' '))\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6559fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDataset(Dataset):\n",
    "    def __init__(self, df, word_dict, max_length):\n",
    "        self.df = df\n",
    "        self.word_dict = word_dict\n",
    "        self.max_len = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        posting = row['cleaned'].split(' ')\n",
    "        x = torch.zeros(self.max_len)\n",
    "        \n",
    "        for idx in range(len(posting)):\n",
    "            \n",
    "            # we want to front pad for RNN\n",
    "            x[self.max_len - len(posting) + idx] = self.word_dict.get(posting[idx],0)\n",
    "            \n",
    "        y = torch.tensor(row['fraudulent']).float()\n",
    "        \n",
    "        # embedding likes long tensors\n",
    "        return x.long(), y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f05b5f-1c74-434c-bc72-b6a0f60dec48",
   "metadata": {},
   "source": [
    "## RNN model with GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c4c25a5-3aa6-4325-b66e-2b1fc80daa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIGRU(nn.Module):\n",
    "    def __init__(self,word_dict, embedding_size, hidden_size):\n",
    "        super(BIGRU, self).__init__()\n",
    "        \n",
    "        self.word_dict = word_dict\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # integer to word dictionary\n",
    "        self.idx2word = dict([(x, y) for x, y in zip(self.word_dict.values(), self.word_dict.keys())])\n",
    "        self.idx2word[0] = 'UNK'\n",
    "        \n",
    "        # length of dictionary\n",
    "        dict_length = max(word_dict.values()) + 1\n",
    "        \n",
    "        # embed the words\n",
    "        self.emb = nn.Embedding(dict_length, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear = nn.Linear(hidden_size, 1) # input dim is 64*2 because its bidirectional\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.emb(x)\n",
    "        x, h = self.gru(x, h)\n",
    "        x = self.dropout(x[:,-1,:].squeeze()) # just get the last hidden state\n",
    "        x = self.linear(x) # sigmoid output for binary classification\n",
    "        return x.squeeze()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return autograd.Variable(torch.randn(1, 1000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "797aaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_pass(model,h, dataloader, optimizer, lossFun, backwards=True, print_loss=False):\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_incorrect = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    len_ = 0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        if len(x)==1000:\n",
    "            y_pred = model(x,h)\n",
    "            loss = lossFun(y_pred, y.float())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if backwards == True:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            y_pred = torch.sigmoid(y_pred).round().long()\n",
    "            y = y.long()\n",
    "            total_incorrect += torch.count_nonzero(y - y_pred).item()\n",
    "            tp += (y & y_pred).sum()\n",
    "            fp += (y_pred & (~y)).sum()\n",
    "            fn = ((~y_pred) & y).sum()\n",
    "            len_ += x.shape[0]\n",
    "    \n",
    "        percent_wrong = total_incorrect / len_\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        if print_loss == True:\n",
    "            print(avg_loss)\n",
    "    \n",
    "    return np.round(1-percent_wrong,2),np.round((tp/(tp+fp)).numpy(),2),np.round((tp/(tp+fn)).numpy(),2)\n",
    "\n",
    "def one_pass_acc(model,h,dataloader):\n",
    "    model.eval()\n",
    "    total_incorrect = 0\n",
    "    total_loss = 0.0\n",
    "    total_incorrect = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    len_ = 0    \n",
    "    for x, y in dataloader:\n",
    "        print (len(x))\n",
    "        if len(x)==1000:\n",
    "            y_pred = torch.sigmoid(model(x,h)).round().long()\n",
    "            y = y.long()\n",
    "            total_incorrect += torch.count_nonzero(y - y_pred).item()\n",
    "            tp += (y & y_pred).sum()\n",
    "            fp += (y_pred & (~y)).sum()\n",
    "            fn = ((~y_pred) & y).sum()\n",
    "            len_ += x.shape[0]\n",
    "    \n",
    "        percent_wrong = total_incorrect / len_\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    return np.round(1-percent_wrong,2),np.round((tp/(tp+fp)).numpy(),2),np.round((tp/(tp+fn)).numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "99ae4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = JobDataset(df_train, word_dict, max_length)\n",
    "ds_valid = JobDataset(df_valid, word_dict, max_length)\n",
    "dl_train = DataLoader(ds_train, batch_size=1000, shuffle=True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6e1a31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "model = BIGRU(word_dict, embedding_size=100, hidden_size=100)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e2cfbd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99993e0c8b3422dbb187e367d448a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dd0eef8d2c4b1f88b3821f783594f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.9 train precision:  0.06 train recall:  0.56\n",
      "valid accuracy:  0.95 valid precision:  0.71 valid recall:  0.08\n",
      "Epoch:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fe1388fc7b44e2bbdb6b55481f5da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.96 train precision:  0.86 train recall:  0.67\n",
      "valid accuracy:  0.96 valid precision:  0.87 valid recall:  0.3\n",
      "Epoch:  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d247245463f4e7484b61e20b2fea7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.96 train precision:  0.84 train recall:  0.85\n",
      "valid accuracy:  0.97 valid precision:  0.93 valid recall:  0.53\n",
      "Epoch:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a062f0adf04b23b7cbe4cd0c383f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.97 train precision:  0.89 train recall:  0.89\n",
      "valid accuracy:  0.97 valid precision:  0.95 valid recall:  0.49\n",
      "Epoch:  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3d0400791541dcb03ef8de357cfc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.98 train precision:  0.92 train recall:  0.94\n",
      "valid accuracy:  0.97 valid precision:  0.89 valid recall:  0.62\n",
      "Epoch:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e28da1241414c15a80e8f7e091ce3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.99 train precision:  0.95 train recall:  0.99\n",
      "valid accuracy:  0.98 valid precision:  0.91 valid recall:  0.7\n",
      "Epoch:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74471ff0255477f863b82662bc3576a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  0.99 train precision:  0.98 train recall:  0.99\n",
      "valid accuracy:  0.98 valid precision:  0.9 valid recall:  0.72\n",
      "Epoch:  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff19dc748a423ea887a50df56fbabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  1.0 train precision:  0.98 train recall:  1.0\n",
      "valid accuracy:  0.98 valid precision:  0.87 valid recall:  0.74\n",
      "Epoch:  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003d12a951ee4f24825bf537eb881919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  1.0 train precision:  0.99 train recall:  1.0\n",
      "valid accuracy:  0.98 valid precision:  0.88 valid recall:  0.72\n",
      "Epoch:  9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d8e8fff0b54a37be0d3ee5285190f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "682\n",
      "train accuracy:  1.0 train precision:  0.99 train recall:  1.0\n",
      "valid accuracy:  0.97 valid precision:  0.88 valid recall:  0.69\n"
     ]
    }
   ],
   "source": [
    "h = model.init_hidden()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    acc_train,prec_train,recall_train = one_pass(model,h,dl_train, optimizer, lossFun)\n",
    "    acc_val,prec_val,recall_val = one_pass_acc(model,h, dl_valid)\n",
    "    print('train accuracy: ', acc_train,'train precision: ',prec_train,'train recall: ',recall_train)\n",
    "    print('valid accuracy: ', acc_val,'valid precision: ',prec_val,'valid recall: ',recall_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52305cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = JobDataset(df_test, word_dict, max_length)\n",
    "dl_test = DataLoader(ds_test, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b79c0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_val,prec_val,recall_val = one_pass_acc(model,h, dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d1951321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c3501",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f7808e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    # Preprocessing parameeters\n",
    "    seq_len: int = 994\n",
    "    num_words: int = 73210\n",
    "\n",
    "    # Model parameters\n",
    "    embedding_size: int = 128\n",
    "    out_size: int = 32\n",
    "    stride: int = 2\n",
    "\n",
    "    # Training parameters\n",
    "    epochs: int = 10\n",
    "    batch_size: int = 12\n",
    "    learning_rate: float = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "57275d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fbe08f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,word_dict):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.word_dict = word_dict\n",
    "        \n",
    "      # Parameters regarding text preprocessing\n",
    "        self.seq_len = params.seq_len\n",
    "        self.num_words = params.num_words\n",
    "        self.embedding_size = params.embedding_size\n",
    "\n",
    "        # Dropout definition\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # CNN parameters definition\n",
    "        # Kernel sizes\n",
    "        self.kernel_1 = 2\n",
    "        self.kernel_2 = 3\n",
    "        self.kernel_3 = 3\n",
    "        self.kernel_4 = 2\n",
    "\n",
    "        # Output size for each convolution\n",
    "        self.out_size = params.out_size\n",
    "        # Number of strides for each convolution\n",
    "        self.stride = params.stride\n",
    "\n",
    "        # Embedding layer definition\n",
    "        self.embedding = nn.Embedding(self.num_words + 1, self.embedding_size, padding_idx=0)\n",
    "\n",
    "        # Convolution layers definition\n",
    "        self.conv_1 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_1, self.stride)\n",
    "        self.conv_2 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_2, self.stride)\n",
    "        self.conv_3 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_3, self.stride)\n",
    "        self.conv_4 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_4, self.stride)\n",
    "\n",
    "        # Max pooling layers definition\n",
    "        self.pool_1 = nn.MaxPool1d(self.kernel_1, self.stride)\n",
    "        self.pool_2 = nn.MaxPool1d(self.kernel_2, self.stride)\n",
    "        self.pool_3 = nn.MaxPool1d(self.kernel_3, self.stride)\n",
    "        self.pool_4 = nn.MaxPool1d(self.kernel_4, self.stride)\n",
    "\n",
    "        # Fully connected layer definition\n",
    "        self.fc = nn.Linear(self.in_features_fc(), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Sequence of tokes is filterd through an embedding layer\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Convolution layer 1 is applied\n",
    "        x1 = self.conv_1(x)\n",
    "        x1 = torch.relu(x1)\n",
    "        x1 = self.pool_1(x1)\n",
    "\n",
    "        # Convolution layer 2 is applied\n",
    "        x2 = self.conv_2(x)\n",
    "        x2 = torch.relu((x2))\n",
    "        x2 = self.pool_2(x2)\n",
    "\n",
    "        # Convolution layer 3 is applied\n",
    "        x3 = self.conv_3(x)\n",
    "        x3 = torch.relu(x3)\n",
    "        x3 = self.pool_3(x3)\n",
    "\n",
    "        # Convolution layer 4 is applied\n",
    "        x4 = self.conv_4(x)\n",
    "        x4 = torch.relu(x4)\n",
    "        x4 = self.pool_4(x4)\n",
    "\n",
    "        # The output of each convolutional layer is concatenated into a unique vector\n",
    "        union = torch.cat((x1, x2, x3, x4), 2)\n",
    "        union = union.reshape(union.size(0), -1)\n",
    "\n",
    "        # The \"flattened\" vector is passed through a fully connected layer\n",
    "        out = self.fc(union)\n",
    "        # Dropout is applied\n",
    "        out = self.dropout(out)\n",
    "        # Activation function is applied\n",
    "#         out = torch.sigmoid(out)\n",
    "\n",
    "        return out.squeeze()\n",
    "\n",
    "    def in_features_fc(self):\n",
    "        '''Calculates the number of output features after Convolution + Max pooling\n",
    "\n",
    "        Convolved_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1\n",
    "        Pooled_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1\n",
    "\n",
    "        source: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        '''\n",
    "        # Calcualte size of convolved/pooled features for convolution_1/max_pooling_1 features\n",
    "        out_conv_1 = ((self.embedding_size - 1 * (self.kernel_1 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_1 = math.floor(out_conv_1)\n",
    "        out_pool_1 = ((out_conv_1 - 1 * (self.kernel_1 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_1 = math.floor(out_pool_1)\n",
    "\n",
    "        # Calcualte size of convolved/pooled features for convolution_2/max_pooling_2 features\n",
    "        out_conv_2 = ((self.embedding_size - 1 * (self.kernel_2 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_2 = math.floor(out_conv_2)\n",
    "        out_pool_2 = ((out_conv_2 - 1 * (self.kernel_2 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_2 = math.floor(out_pool_2)\n",
    "\n",
    "        # Calcualte size of convolved/pooled features for convolution_3/max_pooling_3 features\n",
    "        out_conv_3 = ((self.embedding_size - 1 * (self.kernel_3 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_3 = math.floor(out_conv_3)\n",
    "        out_pool_3 = ((out_conv_3 - 1 * (self.kernel_3 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_3 = math.floor(out_pool_3)\n",
    "\n",
    "        # Calcualte size of convolved/pooled features for convolution_4/max_pooling_4 features\n",
    "        out_conv_4 = ((self.embedding_size - 1 * (self.kernel_4 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_4 = math.floor(out_conv_4)\n",
    "        out_pool_4 = ((out_conv_4 - 1 * (self.kernel_4 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_4 = math.floor(out_pool_4)\n",
    "\n",
    "    # Returns \"flattened\" vector (input for fully connected layer)\n",
    "        return (out_pool_1 + out_pool_2 + out_pool_3 + out_pool_4) * self.out_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "73200d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_pass(model,dataloader, optimizer, lossFun, backwards=True, print_loss=False):\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_incorrect = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    len_ = 0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        y_pred = model(x)\n",
    "        loss = lossFun(y_pred, y.float())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        y_pred = torch.sigmoid(y_pred).round().long()\n",
    "        y = y.long()\n",
    "        total_incorrect += torch.count_nonzero(y - y_pred).item()\n",
    "        tp += (y & y_pred).sum()\n",
    "        fp += (y_pred & (~y)).sum()\n",
    "        fn = ((~y_pred) & y).sum()\n",
    "        len_ += x.shape[0]\n",
    "    \n",
    "    percent_wrong = total_incorrect / len_\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    if print_loss == True:\n",
    "        print(avg_loss)\n",
    "    \n",
    "    return np.round(1-percent_wrong,2),np.round((tp/(tp+fp)).numpy(),2),np.round((tp/(tp+fn)).numpy(),2)\n",
    "\n",
    "def one_pass_acc(model,dataloader):\n",
    "    model.eval()\n",
    "    total_incorrect = 0\n",
    "    total_loss = 0.0\n",
    "    total_incorrect = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    len_ = 0    \n",
    "    for x, y in dataloader:\n",
    "        y_pred = torch.sigmoid(model(x)).round().long()\n",
    "        y = y.long()\n",
    "        total_incorrect += torch.count_nonzero(y - y_pred).item()\n",
    "        tp += (y & y_pred).sum()\n",
    "        fp += (y_pred & (~y)).sum()\n",
    "        fn = ((~y_pred) & y).sum()\n",
    "        len_ += x.shape[0]\n",
    "    \n",
    "    percent_wrong = total_incorrect / len_\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print (avg_loss)\n",
    "    return np.round(1-percent_wrong,2),np.round((tp/(tp+fp)).numpy(),2),np.round((tp/(tp+fn)).numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2f4b48a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cb7b2a167f485a80e4a07201501552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea27a6f2627d4afab7cbe24360851634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8121737195895269\n",
      "0.0\n",
      "train accuracy:  0.9 train precision:  0.06 train recall:  0.63\n",
      "valid accuracy:  0.95 valid precision:  nan valid recall:  0.0\n",
      "Epoch:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fd45321f9a440fb8764b04049c179e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36265923426701474\n",
      "0.0\n",
      "train accuracy:  0.95 train precision:  1.0 train recall:  0.11\n",
      "valid accuracy:  0.95 valid precision:  1.0 valid recall:  0.13\n",
      "Epoch:  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d53e29eaa84a689555e39cc0b2dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24677899135993078\n",
      "0.0\n",
      "train accuracy:  0.96 train precision:  0.98 train recall:  0.89\n",
      "valid accuracy:  0.97 valid precision:  0.96 valid recall:  0.76\n",
      "Epoch:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afec9da2dfb44d70970548548a513c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20322123972269204\n",
      "0.0\n",
      "train accuracy:  0.98 train precision:  0.99 train recall:  0.97\n",
      "valid accuracy:  0.97 valid precision:  1.0 valid recall:  0.79\n",
      "Epoch:  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6333be9133444eac3c1c0441d4b706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18441756413533136\n",
      "0.0\n",
      "train accuracy:  0.98 train precision:  0.99 train recall:  0.97\n",
      "valid accuracy:  0.97 valid precision:  0.95 valid recall:  0.81\n",
      "Epoch:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46199783450d486f8892fe9b435ff7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.180301036972266\n",
      "0.0\n",
      "train accuracy:  0.99 train precision:  1.0 train recall:  0.98\n",
      "valid accuracy:  0.97 valid precision:  0.98 valid recall:  0.81\n",
      "Epoch:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b669dee19343e8ae2a16925a61b25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17522832063528207\n",
      "0.0\n",
      "train accuracy:  0.99 train precision:  1.0 train recall:  0.98\n",
      "valid accuracy:  0.97 valid precision:  1.0 valid recall:  0.79\n",
      "Epoch:  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be9d38a43e2418eb4e827532d1af47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17563050297590402\n",
      "0.0\n",
      "train accuracy:  0.99 train precision:  1.0 train recall:  0.98\n",
      "valid accuracy:  0.97 valid precision:  0.98 valid recall:  0.81\n",
      "Epoch:  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ec59e6305d49109f24d3e6c268e6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1734794401205503\n",
      "0.0\n",
      "train accuracy:  0.99 train precision:  1.0 train recall:  0.99\n",
      "valid accuracy:  0.97 valid precision:  1.0 valid recall:  0.81\n",
      "Epoch:  9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd7553b0ff744f490013b381a8dd69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17394971732909864\n",
      "0.0\n",
      "train accuracy:  0.99 train precision:  1.0 train recall:  0.98\n",
      "valid accuracy:  0.97 valid precision:  1.0 valid recall:  0.81\n",
      "531.6453187465668\n"
     ]
    }
   ],
   "source": [
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "model = CNN(word_dict)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "num_epochs = 10\n",
    "start = time.time()\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    acc_train,prec_train,recall_train = one_pass(model,dl_train, optimizer, lossFun,print_loss=True)\n",
    "    acc_val,prec_val,recall_val = one_pass_acc(model,dl_valid)\n",
    "    print('train accuracy: ', acc_train,'train precision: ',prec_train,'train recall: ',recall_train)\n",
    "    print('valid accuracy: ', acc_val,'valid precision: ',prec_val,'valid recall: ',recall_val)\n",
    "end = time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "471e3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.97, 0.99, 0.76)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_pass_acc(model,dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a327070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
